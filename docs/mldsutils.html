---

title: mldsutils


keywords: fastai
sidebar: home_sidebar



nb_path: "00_mldsutils.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 00_mldsutils.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="rename_duplicates" class="doc_header"><code>rename_duplicates</code><a href="https://github.com/Tirtha/mldsutils/tree/master/mldsutils/mldsutils.py#L37" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>rename_duplicates</code>(<strong><code>old</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Function-for-running-a-list-of-classifiers">Function for running a list of classifiers<a class="anchor-link" href="#Function-for-running-a-list-of-classifiers"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="run_classifiers" class="doc_header"><code>run_classifiers</code><a href="https://github.com/Tirtha/mldsutils/tree/master/mldsutils/mldsutils.py#L48" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>run_classifiers</code>(<strong><code>X</code></strong>, <strong><code>y</code></strong>, <strong><code>clf_lst</code></strong>=<em><code>[LogisticRegression(C=0.1, n_jobs=-1)]</code></em>, <strong><code>names</code></strong>=<em><code>None</code></em>, <strong><code>num_runs</code></strong>=<em><code>10</code></em>, <strong><code>test_frac</code></strong>=<em><code>0.2</code></em>, <strong><code>scaling</code></strong>=<em><code>True</code></em>, <strong><code>metric</code></strong>=<em><code>'accuracy'</code></em>, <strong><code>runtime</code></strong>=<em><code>False</code></em>, <strong><code>verbose</code></strong>=<em><code>True</code></em>)</p>
</blockquote>
<h3 id="Description">Description<a class="anchor-link" href="#Description"> </a></h3><p>Runs through the list of classifiers for a given number of times</p>
<h3 id="Args:">Args:<a class="anchor-link" href="#Args:"> </a></h3><p><code>X</code>: numpy.ndarray, feature array in the shape of (<em>M X N</em>).
If an array with shape (<em>M</em>,) is passed, the function coerces it to (<em>M X 1</em>) shape</p>
<p><code>y</code>: numpy.ndarray, output array in the shape of (<em>M X 1</em>).
If an array with shape (<em>M</em>,) is passed, the function coerces it to (<em>M X 1</em>) shape</p>
<p><code>clf_lst</code>: list/tutple, A list/tuple of Scikit-learn estimator objects (classifiers)</p>
<p><code>names</code>: list/tuple of strings, Human-readable names/descriptions of the estimators
e.g. <strong><em>Support Vector Machine with Linear Kernel and C=0.025</em></strong> for an estimator object <code>SVC(kernel="linear", C=0.025)</code>.
If not supplied explicitly, then the function tries to extract a suitable name from the estimator class but the result is not optimal.</p>
<p><code>num_runs</code>: int, Number of runs (fitting) per model</p>
<p><code>test_frac</code>: float, Test set fraction</p>
<p><code>scaling</code>: bool, flag to run <code>StandardScaler</code> on the data, default <code>True</code></p>
<p><code>metric</code>: str, name of the ML metric user is interested in. Currently, could be <code>accuracy</code> or <code>f1</code></p>
<p><code>runtime</code>: bool, if <code>True</code>, calculates and returns the fitting time (in milliseconds) along with the ML metric</p>
<p><code>verbose</code>: bool, if <code>True</code>, prints a single-line message after each estimator finishes <code>num_runs</code> runs</p>
<h3 id="Returns:">Returns:<a class="anchor-link" href="#Returns:"> </a></h3><p><code>df_scores</code>: A Pandas DataFrame of score i.e. ML metric that was requested for all the runs.
If <code>num_runs=10</code> then you will have 10 rows in this dataframe. Each classifier/estimator will be a separate column.</p>
<p><code>df_runtimes</code>: A Pandas DataFrame of the training times (in milliseconds) for all the runs and estimators.</p>
<h3 id="Example:">Example:<a class="anchor-link" href="#Example:"> </a></h3>
<pre><code>from sklearn.datasets import make_classification
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from .mldsutils import run_classifiers

X1, y1 = make_classification(n_features=20,
                             n_samples=2000,
                             n_redundant=0,
                             n_informative=20,
                             n_clusters_per_class=1)

classifiers = [
    KNeighborsClassifier(3),
    SVC(kernel="linear", C=0.025),
    SVC(gamma=2, C=10),]

clf_names = ['k-Nearest Neighbors(3)',
             'Support Vector Machine with Linear Kernel',
            'Support Vector Machine with RBF Kernel']

d1,d2 = run_classifiers(X1,y1,
                        clf_lst=classifiers,
                        names = clf_names,
                        metric='f1',verbose=True)</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Plot-function-for-displaying-the-resulting-dataframes">Plot function for displaying the resulting dataframes<a class="anchor-link" href="#Plot-function-for-displaying-the-resulting-dataframes"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="plot_bars" class="doc_header"><code>plot_bars</code><a href="https://github.com/Tirtha/mldsutils/tree/master/mldsutils/mldsutils.py#L178" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>plot_bars</code>(<strong><code>d</code></strong>, <strong><code>t1</code></strong>=<em><code>'Mean accuracy score of algorithms'</code></em>, <strong><code>t2</code></strong>=<em><code>'Std.dev of the accuracy scores of algorithms'</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Running-a-list-of-regressors">Running a list of regressors<a class="anchor-link" href="#Running-a-list-of-regressors"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="run_regressors" class="doc_header"><code>run_regressors</code><a href="https://github.com/Tirtha/mldsutils/tree/master/mldsutils/mldsutils.py#L200" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>run_regressors</code>(<strong><code>X</code></strong>, <strong><code>y</code></strong>, <strong><code>reg_lst</code></strong>=<em><code>[LinearRegression(n_jobs=-1)]</code></em>, <strong><code>names</code></strong>=<em><code>None</code></em>, <strong><code>num_runs</code></strong>=<em><code>10</code></em>, <strong><code>test_frac</code></strong>=<em><code>0.2</code></em>, <strong><code>scaling</code></strong>=<em><code>True</code></em>, <strong><code>metric</code></strong>=<em><code>'rmse'</code></em>, <strong><code>runtime</code></strong>=<em><code>True</code></em>, <strong><code>verbose</code></strong>=<em><code>0</code></em>)</p>
</blockquote>
<h3 id="Description">Description<a class="anchor-link" href="#Description"> </a></h3><p>Runs through the list of classifiers for a given number of times</p>
<h3 id="Args:">Args:<a class="anchor-link" href="#Args:"> </a></h3><p><code>X</code>: numpy.ndarray, feature array in the shape of (<em>M X N</em>).
If an array with shape (<em>M</em>,) is passed, the function coerces it to (<em>M X 1</em>) shape</p>
<p><code>y</code>: numpy.ndarray, output array in the shape of (<em>M X 1</em>).
If an array with shape (<em>M</em>,) is passed, the function coerces it to (<em>M X 1</em>) shape</p>
<p><code>reg_lst</code>: list/tutple, A list/tuple of Scikit-learn estimator objects (regressors)</p>
<p><code>names</code>: list/tuple of strings, Human-readable names/descriptions of the estimators
e.g. <strong><em>LASSO regression with alpha=0.1</em></strong> for an estimator object <code>Lasso(alpha=0.1)</code>.
If not supplied explicitly, then the function tries to extract a suitable name from the estimator class but the result is not optimal.</p>
<p><code>num_runs</code>: int, Number of runs (fitting) per model</p>
<p><code>test_frac</code>: float, Test set fraction</p>
<p><code>scaling</code>: bool, flag to run <code>StandardScaler</code> on the data, default <code>True</code></p>
<p><code>metric</code>: str, name of the ML metric user is interested in. Currently, could be <code>rmse</code> or <code>r2</code></p>
<p><code>runtime</code>: bool, if <code>True</code>, calculates and returns the fitting time (in milliseconds) along with the ML metric</p>
<p><code>verbose</code>: bool, if <code>True</code>, prints a single-line message after each estimator finishes <code>num_runs</code> runs</p>
<h3 id="Returns:">Returns:<a class="anchor-link" href="#Returns:"> </a></h3><p><code>df_scores</code>: A Pandas DataFrame of score i.e. ML metric that was requested for all the runs.
If <code>num_runs=10</code> then you will have 10 rows in this dataframe. Each regressor/estimator will be a separate column.</p>
<p><code>df_runtimes</code>: A Pandas DataFrame of the training times (in milliseconds) for all the runs and estimators.</p>
<h3 id="Example:">Example:<a class="anchor-link" href="#Example:"> </a></h3>
<pre><code>from .mldsutils import *
from sklearn.linear_model import LinearRegression, Lasso, Ridge
import numpy as np

reg_names = ["Linear regression","L1 (LASSO) regression","Ridge regression"]
regressors = [LinearRegression(n_jobs=-1),Lasso(alpha=0.1),Ridge(alpha=0.1)]

X = np.random.normal(size=200)
y = 2*X+3+np.random.uniform(1,2,size=200)

d1 = run_regressors(X,y,regressors,metric='r2',runtime=False,verbose=True)</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="A-test-of-running-the-run_regressors-function">A test of running the <a href="/mldsutils/mldsutils.html#run_regressors"><code>run_regressors</code></a> function<a class="anchor-link" href="#A-test-of-running-the-run_regressors-function"> </a></h2><p>This cell will be used by <code>nbdev</code> for testing</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">X</span><span class="o">+</span><span class="mi">3</span>
<span class="n">d1</span> <span class="o">=</span> <span class="n">run_regressors</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">,</span><span class="n">runtime</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">assert</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">d1</span><span class="p">[</span><span class="s1">&#39;LinearRegression&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.1</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

